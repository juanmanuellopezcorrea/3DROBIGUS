

import pandas as pd
import glob
from sklearn.cluster import KMeans
import os
import pickle

def coordenates(folder_path):
    lstind = []
    lstmc = []
    lstx = []
    lsty = []
    lstz = []
    lsti = []
    for file in glob.glob(folder_path):
        ind = file.split("/")[-1].split("id")[0]
        np = file.split("/")[-1].split("_")[-2]
        with open(file) as f:
            lines = f.readlines()
            for line in lines[11:]:
                lstmc.append(np)
                lstind.append(str(ind))
                x = line.split(" ")[0]
                lstx.append(float(x))
                y = line.split(" ")[1]
                lsty.append(float(y))
                z = line.split(" ")[2]
                lstz.append(float(z))
                i = line.split(" ")[3]
                lsti.append(int(i))
    df = pd.DataFrame(list(zip(lstind, lstmc, lstx, lsty, lstz, lsti)),
                      columns=['id', 'maceta', 'Px', 'Py', 'Pz', 'intensity'])




def helloply(save_path, Px, Py, Pz, inti):
    n = len(Px)
    Px = Px.to_list()
    Py = Py.to_list()
    Pz = Pz.to_list()
    inti = inti.to_list()
    lst = [(Px), Py, Pz, inti]
    print("ok")
    with open(save_path, "w") as file:
        # Writing data to a file
        file.writelines("ply \n")
        file.writelines("format ascii 1.0 \n")
        file.write("comment Created by CloudCompare v2.12 alpha \n")
        file.write("comment Created 10/6/2021 9:45 AM \n")
        file.write("obj_info Generated by CloudCompare! \n")
        file.write("element vertex ")
        file.write(str(n) + "\n")
        file.write("property float x \n")
        file.write("property float y \n")
        file.write("property float z \n")
        file.write("property float scalar_intensity \n")
        file.write("end_header \n")
        for x in zip(*lst):
            file.write("{0}\t{1}\t{2}\t{3}\n".format(*x))


def height_point_clouds(folder_path, df, pp):
    nplant = []
    fechal = []
    lstheight = []
    wheat_typelst = []

    for file in glob.glob(folder_path):
        np = file.split("/")[-1].split("_")[1].split(".")[0]
        nplant.append(np)
        f = file.split("/")[-4].split("_rob")[0]
        fechal.append(f)
        twl = file.split("/")[-3]
        wheat_typelst.append(twl)
        df_1 = df.loc[(df["n_plant"] == np)]
        height = height_point(df_1, pp)
        lstheight.append(height)

    df_heights = pd.DataFrame(list(zip(fechal, wheat_typelst, nplant, lstheight)),
                              columns=['fecha', 'wheat_type', 'plant number', 'height'])

    return df_heights


def point_cloud_volume(df_1, pv,ph):
    """
    Parameters
    ----------
    folder_path : TYPE : str
        DESCRIPTION :carperta con los los archivos.
    df : TYPE : dataframe
        DESCRIPTION: dataframe con los columns =['fecha', 'wheat_type','n_plant','Px','Py','Pz','intensity'])
    p : TYPE: int
        DESCRIPTION: proporción de nubes de puntos ocn los cuál se desea calcular la altura

    Returns
    -------
    df_heights : TYPE : dataframe
        DESCRIPTION : dataframe con columns =['fecha', 'wheat_type','plant number','height'])

    """

    minvalue_Py = df_1.Py.min()  #
    minvalue_Px = df_1.Px.min()  #
    maxvalue_Py = df_1.Py.max()
    maxvalue_Px = df_1.Px.max()
    ran_Py = (maxvalue_Py - minvalue_Py)
    ran_Px = (maxvalue_Px - minvalue_Px)

    pymax = maxvalue_Py - (ran_Py * pv / 100)
    pymin = minvalue_Py + (ran_Py * pv / 100)

    pxmin = minvalue_Px + (ran_Px * pv / 100)
    pxmax = maxvalue_Px - (ran_Px * pv / 100)

    df_pymax = df_1.loc[(df_1.Py > pymax)]
    df_pxmax = df_1.loc[(df_1.Px > pxmax)]

    df_pymin = df_1.loc[(df_1.Py < pymin)]
    df_pxmin = df_1.loc[(df_1.Px < pxmin)]

    wigth = df_pymax.Py.mean() - df_pymin.Py.mean()  # Py ancho weigth

    depht = df_pxmax.Px.mean() - df_pxmin.Px.mean()  # Px las prof depth

    height = height_point(df_1, ph)  # el alto es considerado como con el suelo

    volume = wigth * depht * height

    proy = wigth * depht

    return wigth, depht, height, volume, proy


def clipsoil(df_1, pp):

    """
    file: archivo ply
    pp:  proporcion que se quita del  (- Pz) desde el Pz.min

    """


    rang = df_1.Pz.max() - df_1.Pz.min()
    plano_min = df_1.Pz.min() + (rang * pp / 100)
    df_clip = df_1.loc[(df_1.Pz > plano_min)]  # puntos cortados

    return df_clip


def height_point(df_1, ph):
    # TODO realizar metodo de la función para que lo calculé a partir del Pz=0

    """
    Parameters
    ----------
    file : TYPE : dataframe df_1
        DESCRIPTION : with Px, Py, Pz, intensity

    ph : TYPE: int
        DESCRIPTION: proporción de nubes de puntos ocn los cuál se desea calcular la altura

    Returns
    -------
    height : TYPE : float
        DESCRIPTION : hieght
    """

    maxvalue = df_1.Pz.max()
    pzmaxs = maxvalue - (maxvalue * ph * 2 / 100)
    df_pzmaxs = df_1.loc[(df_1.Pz > pzmaxs)]
    height = df_pzmaxs.Pz.mean()
    print("height id:", df_1.id.unique()[0], height)

    return height


def density_height_points(df_1, pd):
    pd=100-pd
    df_clip = clipsoil(df_1, pd)
    npoint = df_clip.shape[0]
    return npoint


def intensity_heigtht_points(df_1, pi):
    pi = 100 - pi
    df_clip = clipsoil(df_1, pi)
    pinti = df_clip.intensity.mean()

    return pinti



def kmeans_train(df_train, lstk, path_models):
    path_models = os.path.join(path_models, "models")
    for k in lstk:
        kmeans = KMeans(n_clusters=k, random_state=42).fit(df_train)
        name="kmeans_models_"+str(k)+"_cl.pickle"

        if not os.path.exists(path_models):
            # Create a new directory because it does not exist
            os.makedirs(path_models)
            print("kmeans model saved!")
        name = "kmeans_models_" + str(k) + "_cl.pickle"
        name=os.path.join(path_models,name)
        with open (name, 'wb') as ds:
            pickle.dump(kmeans,ds,protocol=pickle.HIGHEST_PROTOCOL)

def kmeans_pred(df_test,folder_models):
    df_pred = pd.DataFrame()
    for pik in glob.glob(folder_models):
        with open(pik, 'rb') as ds:
            kmeans_model=pickle.load(ds)
        kmeans_pred = kmeans_model.predict(df_test)
        kmeans_pred = kmeans_pred.tolist()
        num=pik.split("models_")[-1].split("_")[0]
        df_pred["kmeans_" + str(num)] = kmeans_pred

    return df_pred



