

import pandas as pd
import glob
from sklearn.cluster import KMeans
import os
import pickle

def coordenates(folder_path):
    fecha = []
    wheat_type = []
    n_plant = []
    lstx = []
    lsty = []
    lstz = []
    lsti = []
    nlst=[]
    for file in glob.glob(folder_path):
        n=file.split("_")[-1].split(".ply")[0]
        np = file.split("_")[-3]
        tw = file.split("/")[-3]
        fc=file.split("/")[-4]
        with open(file) as f:
            lines = f.readlines()
            for line in lines[11:]:
                fecha.append(fc)
                wheat_type.append(tw)
                n_plant.append(np)
                x = line.split(" ")[0]
                lstx.append(float(x))
                y = line.split(" ")[1]
                lsty.append(float(y))
                z = line.split(" ")[2]
                lstz.append(float(z))
                i = line.split(" ")[3]
                lsti.append(int(i))
                nlst.append(str(n))


    df = pd.DataFrame(list(zip(nlst,fecha, wheat_type, n_plant, lstx, lsty, lstz, lsti)),
                      columns=['id','fecha', 'wheat_type', 'n_plant', 'Px', 'Py', 'Pz', 'intensity'])

    return df


def helloply(save_path, Px, Py, Pz, inti):
    n = len(Px)
    Px = Px.to_list()
    Py = Py.to_list()
    Pz = Pz.to_list()
    inti = inti.to_list()
    lst = [(Px), Py, Pz, inti]
    print("ok")
    with open(save_path, "w") as file:
        # Writing data to a file
        file.writelines("ply \n")
        file.writelines("format ascii 1.0 \n")
        file.write("comment Created by CloudCompare v2.12 alpha \n")
        file.write("comment Created 10/6/2021 9:45 AM \n")
        file.write("obj_info Generated by CloudCompare! \n")
        file.write("element vertex ")
        file.write(str(n) + "\n")
        file.write("property float x \n")
        file.write("property float y \n")
        file.write("property float z \n")
        file.write("property float scalar_intensity \n")
        file.write("end_header \n")
        for x in zip(*lst):
            file.write("{0}\t{1}\t{2}\t{3}\n".format(*x))


def height_point_clouds(folder_path, df, pp):
    nplant = []
    fechal = []
    lstheight = []
    wheat_typelst = []

    for file in glob.glob(folder_path):
        np = file.split("/")[-1].split("_")[1].split(".")[0]
        nplant.append(np)
        f = file.split("/")[-4].split("_rob")[0]
        fechal.append(f)
        twl = file.split("/")[-3]
        wheat_typelst.append(twl)
        df_1 = df.loc[(df["n_plant"] == np)]
        height = height_point(df_1, pp)
        lstheight.append(height)

    df_heights = pd.DataFrame(list(zip(fechal, wheat_typelst, nplant, lstheight)),
                              columns=['fecha', 'wheat_type', 'plant number', 'height'])

    return df_heights


def point_cloud_volume(df_1, pp, pv):
    """
    Parameters
    ----------
    folder_path : TYPE : str
        DESCRIPTION :carperta con los los archivos.
    df : TYPE : dataframe
        DESCRIPTION: dataframe con los columns =['fecha', 'wheat_type','n_plant','Px','Py','Pz','intensity'])
    p : TYPE: int
        DESCRIPTION: proporción de nubes de puntos ocn los cuál se desea calcular la altura

    Returns
    -------
    df_heights : TYPE : dataframe
        DESCRIPTION : dataframe con columns =['fecha', 'wheat_type','plant number','height'])

    """

    df_v = clipsoil(df_1, pp)  # Corte del plano

    minvalue_Py = df_v.Py.min()  #
    minvalue_Px = df_v.Px.min()  #
    maxvalue_Py = df_v.Py.max()
    maxvalue_Px = df_v.Px.max()
    ran_Py = (maxvalue_Py - minvalue_Py)
    ran_Px = (maxvalue_Px - minvalue_Px)

    pymax = maxvalue_Py - (ran_Py * pv / 100)
    pymin = minvalue_Py + (ran_Py * pv / 100)

    pxmax = maxvalue_Px - (ran_Px * pv / 100)
    pxmin = minvalue_Px + (ran_Px * pv / 100)

    df_pymax = df_v.loc[(df_v.Py > pymax)]
    df_pxmax = df_v.loc[(df_v.Px > pxmax)]

    df_pymin = df_v.loc[(df_v.Py < pymin)]
    df_pxmin = df_v.loc[(df_v.Px < pxmin)]

    wigth = df_pymax.Py.mean() - df_pymin.Py.mean()  # Py ancho weigth

    depht = df_pxmax.Px.mean() - df_pxmin.Px.mean()  # Px las prof depth

    height = height_point(df_1, pp)  # el alto es considerado como con el suelo

    volume = wigth * depht * height

    proy = wigth * depht

    return wigth, depht, height, volume, proy


def clipsoil(df_1, pp):
    """
    file: archivo ply
    pp:  proporcion que se quita del  (- Pz) desde el Pz.min

    """

    minvalue_Pz = df_1.Pz.min()
    plano_min = minvalue_Pz - (minvalue_Pz * pp / 100)
    df_clip = df_1.loc[(df_1.Pz > plano_min)]  # puntos cortados

    return df_clip


def height_point(df_1, ph):
    # TODO realizar metodo de la función para que lo calculé a partir del Pz=0

    """
    Parameters
    ----------
    file : TYPE : str
        DESCRIPTION :file.ply .

    p : TYPE: int
        DESCRIPTION: proporción de nubes de puntos ocn los cuál se desea calcular la altura

    Returns
    -------
    height : TYPE : float
        DESCRIPTION : hieght
    """

    minvalue = df_1.Pz.min()
    maxvalue = df_1.Pz.max()
    ran = (minvalue - maxvalue) * (-1)
    pzmaxs = maxvalue - (ran * ph / 100)
    df_pzmaxs = df_1.loc[(df_1.Pz > pzmaxs)]
    height = df_pzmaxs.Pz.mean()

    return height


def density_height_points(df_1, pd):
    df_clip = clipsoil(df_1, pd)
    npoint = df_clip.shape[0]

    return npoint


def intensity_heigtht_points(df_1, pp):
    df_clip = clipsoil(df_1, pp)
    pinti = df_clip.intensity.mean()

    return pinti



def kmeans_train(df_train, lstk, path_models):
    path_models = os.path.join(path_models, "models")
    for k in lstk:
        kmeans = KMeans(n_clusters=k, random_state=42).fit(df_train)
        name="kmeans_models_"+str(k)+"_cl.pickle"

        if not os.path.exists(path_models):
            # Create a new directory because it does not exist
            os.makedirs(path_models)
            print("kmeans model saved!")
        name = "kmeans_models_" + str(k) + "_cl.pickle"
        name=os.path.join(path_models,name)
        with open (name, 'wb') as ds:
            pickle.dump(kmeans,ds,protocol=pickle.HIGHEST_PROTOCOL)

def kmeans_pred(df_test,folder_models):
    df_pred = pd.DataFrame()
    for pik in glob.glob(folder_models):
        with open(pik, 'rb') as ds:
            kmeans_model=pickle.load(ds)
        kmeans_pred = kmeans_model.predict(df_test)
        kmeans_pred = kmeans_pred.tolist()
        num=pik.split("models_")[-1].split("_")[0]
        df_pred["kmeans_" + str(num)] = kmeans_pred

    return df_pred



